import xgboost as xgb
from sklearn.metrics import mean_squared_error

class XGBoostModel:
    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):
        self.n_estimators = n_estimators
        self.learning_rate = learning_rate
        self.max_depth = max_depth
        self.model = None

    def fit(self, X, y):
        self.model = xgb.XGBRegressor(n_estimators=self.n_estimators, learning_rate=self.learning_rate, max_depth=self.max_depth)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

def test_xgboost(X_train, y_train, X_test, y_test):
    model = XGBoostModel()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    return mse

# Example usage
# Split the data into training and testing sets
X_train = train_data.drop('target', axis=1)
y_train = train_data['target']
X_test = test_data.drop('target', axis=1)
y_test = test_data['target']

# Train and test the XGBoost model
xgboost = XGBoostModel()
xgboost.fit(X_train, y_train)
mse = test_xgboost(X_train, y_train, X_test, y_test)
print("Mean Squared Error:", mse)

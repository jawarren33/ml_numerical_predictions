import numpy as np
import tensorflow as tf
from sklearn.metrics import mean_squared_error

class NeuralNetworkModel:
    def __init__(self, hidden_layers=(64, 32), learning_rate=0.001, epochs=100, batch_size=32):
        self.hidden_layers = hidden_layers
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        self.models = []

    def create_model(self, input_dim):
        model = tf.keras.models.Sequential()
        model.add(tf.keras.layers.Dense(self.hidden_layers[0], activation='relu', input_dim=input_dim))
        for units in self.hidden_layers[1:]:
            model.add(tf.keras.layers.Dense(units, activation='relu'))
        model.add(tf.keras.layers.Dense(1))  # Output layer
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),
                      loss='mean_squared_error')
        return model

    def fit(self, X, y):
        input_dim = X.shape[1]
        for _ in range(len(self.hidden_layers)):
            model = self.create_model(input_dim)
            model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)
            self.models.append(model)

    def predict(self, X):
        predictions = []
        for model in self.models:
            predictions.append(model.predict(X))
        return np.mean(predictions, axis=0)

def test_neural_network(X_train, y_train, X_test, y_test):
    model = NeuralNetworkModel()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    return mse

# Example usage
# Split the data into training and testing sets
X_train = train_data.drop('target', axis=1)
y_train = train_data['target']
X_test = test_data.drop('target', axis=1)
y_test = test_data['target']

# Train and test the neural network model
neural_network = NeuralNetworkModel()
neural_network.fit(X_train, y_train)
mse = test_neural_network(X_train, y_train, X_test, y_test)
print("Mean Squared Error:", mse)
